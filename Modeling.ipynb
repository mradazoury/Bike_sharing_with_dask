{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# To automatically reload the function file \n",
    "%load_ext autoreload\n",
    "%aimport My_functions\n",
    "%run My_functions.py\n",
    "%autoreload 1\n",
    "%matplotlib inline\n",
    "warnings.simplefilter(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling for Working days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "wd_h=dd.read_csv('workingdays_data_prepared.csv' , blocksize = 71e4)\n",
    "# wd_h['dteday']=pd.to_datetime(wd_h['dteday'], format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wd_h.npartitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the working days prepared dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Train = wd_h[\n",
    "    wd_h[\"instant\"]\n",
    "    < 15212\n",
    "].drop(\n",
    "    [\"cnt\", \"casual\", \"registered\", \"dteday\",'instant','workingday','holiday'], axis=1\n",
    ")  \n",
    "X_Test = wd_h[\n",
    "    (\n",
    "        wd_h[\"instant\"]\n",
    "    >= 15212\n",
    "    )\n",
    "].drop(\n",
    "    [\"cnt\", \"casual\", \"registered\", \"dteday\",'instant','workingday','holiday'], axis=1\n",
    ")  ## NONE OF THEM IN DATA\n",
    "Y_cnt_test = wd_h[\n",
    "    (\n",
    "        wd_h[\"instant\"]\n",
    "    >= 15212\n",
    "    )\n",
    "]['cnt']\n",
    "Y_cnt_train = wd_h[\n",
    "    wd_h[\"instant\"]\n",
    "    < 15212\n",
    "][\"cnt\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7925879627114157"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Linear Regression\n",
    "lm_parameters = {'fit_intercept':[True,False] ,'normalize':[True,False]}\n",
    "\n",
    "lm = dcv.GridSearchCV(LinearRegression(),\n",
    "                                 param_grid=lm_parameters,\n",
    "                                 cv=tscv ,return_train_score=True)\n",
    "with joblib.parallel_backend('dask'):\n",
    "    lm.fit(X_Train, Y_cnt_train)\n",
    "lm.cv_results_\n",
    "lm_predictions_w = lm.predict(X_Test)\n",
    "lm.score(X_Test, Y_cnt_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8406789827196025"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF_parameters = {'n_estimators': [10, 30 ,100],\n",
    "                                             'bootstrap': [True],\n",
    "                                             'max_depth': [80, 100 ],\n",
    "                                             'max_features': ['sqrt',16 ,32],\n",
    "                                             'min_samples_leaf': [2,  5 , 8],\n",
    "                                             'min_samples_split': [ 10 , 8 , 15],\n",
    "                                            'random_state':[random_seed],\n",
    "                                             \"n_jobs\": [-1],\n",
    "                                            'criterion':['mse']}\n",
    "rf = dcv.GridSearchCV(RandomForestRegressor(),\n",
    "                                 param_grid= RF_parameters,\n",
    "                                 cv=tscv)\n",
    "with joblib.parallel_backend('dask'):\n",
    "    rf.fit(X_Train, Y_cnt_train)\n",
    "rf.cv_results_\n",
    "rf_predictions_w = rf.predict(X_Test)\n",
    "rf.score(X_Test, Y_cnt_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8910182851771361"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    \"learning_rate\": [0.01, 0.1],\n",
    "    \"max_depth\": [4, 8, 12],\n",
    "    \"min_child_weight\": [3, 5, 10, 20, 35, 50],\n",
    "    \"subsample\": [0.5, 0.75],\n",
    "    \"colsample_bytree\": [0.5, 0.75],\n",
    "    \"n_jobs\": [-1],\n",
    "    \"n_estimators\": [100, 300],\n",
    "    \"random_state\": [random_seed],\n",
    "}\n",
    "model = xgb.XGBRegressor()\n",
    "\n",
    "xg = dcv.GridSearchCV(model, param_grid=param_grid, cv=tscv, n_jobs=-1, scoring=\"r2\")\n",
    "with joblib.parallel_backend(\"dask\"):\n",
    "    xg.fit(X_Train, Y_cnt_train)\n",
    "para = xg.best_params_\n",
    "xg = dxgb.XGBRegressor(\n",
    "    learning_rate=para[\"learning_rate\"],\n",
    "    max_depth=para[\"max_depth\"],\n",
    "    min_child_weight=para[\"min_child_weight\"],\n",
    "    subsample=para[\"subsample\"],\n",
    "    colsample_bytree=para[\"colsample_bytree\"],\n",
    "    n_estimators=para[\"n_estimators\"],\n",
    ")\n",
    "with joblib.parallel_backend(\"dask\"):\n",
    "    xg.fit(X_Train, Y_cnt_train)\n",
    "\n",
    "xg_predictions_w  = xg.predict(X_Test)\n",
    "xg.score(X_Test, Y_cnt_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_w = dd.concat([xg_predictions_w , wd_h[wd_h[\"instant\"] >= 15212][\"instant\"]] ,  axis = 1)\n",
    "real_pred_w = dd.concat([Y_cnt_test , wd_h[wd_h[\"instant\"] >= 15212][\"instant\"]] ,  axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling for Holidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "hd_h=dd.read_csv('holidays_data_prepared.csv' , blocksize = 40e4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the holidays prepared dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Train_h = hd_h[\n",
    "    hd_h[\"instant\"]\n",
    "    < 15212\n",
    "].drop(\n",
    "    [\"cnt\", \"casual\", \"registered\", \"dteday\",'instant','workingday','holiday'], axis=1\n",
    ")  \n",
    "X_Test_h = hd_h[\n",
    "    (\n",
    "        hd_h[\"instant\"]\n",
    "    >= 15212\n",
    "    )\n",
    "].drop(\n",
    "    [\"cnt\", \"casual\", \"registered\", \"dteday\",'instant','workingday','holiday'], axis=1\n",
    ")  ## NONE OF THEM IN DATA\n",
    "Y_cnt_test_h = hd_h[\n",
    "    (\n",
    "        hd_h[\"instant\"]\n",
    "    >= 15212\n",
    "    )\n",
    "]['cnt']\n",
    "Y_cnt_train_h = hd_h[\n",
    "    hd_h[\"instant\"]\n",
    "    < 15212\n",
    "][\"cnt\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.5671181904079567e+22"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Linear Regression\n",
    "lm_parameters = {'fit_intercept':[True,False] ,'normalize':[True,False]}\n",
    "\n",
    "lm = GridSearchCV(LinearRegression(),\n",
    "                                 param_grid=lm_parameters,\n",
    "                                 cv=tscv ,return_train_score=True)\n",
    "with joblib.parallel_backend('dask'):\n",
    "    lm.fit(X_Train_h, Y_cnt_train_h)\n",
    "lm.cv_results_\n",
    "lm_predictions_h = lm.predict(X_Test_h)\n",
    "lm.score(X_Test_h, Y_cnt_test_h)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8251328564266366"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF_parameters = {'n_estimators': [10, 30 ,100],\n",
    "                                             'bootstrap': [True],\n",
    "                                             'max_depth': [80, 100 ],\n",
    "                                             'max_features': ['sqrt',16 ,32],\n",
    "                                             'min_samples_leaf': [2,  5 , 8],\n",
    "                                             'min_samples_split': [ 10 , 8 , 15],\n",
    "                                            'random_state':[random_seed],\n",
    "                                             \"n_jobs\": [-1],\n",
    "                                            'criterion':['mse']}\n",
    "rf = GridSearchCV(RandomForestRegressor(),\n",
    "                                 param_grid= RF_parameters,\n",
    "                                 cv=tscv)\n",
    "with joblib.parallel_backend('dask'):\n",
    "    rf.fit(X_Train_h, Y_cnt_train_h)\n",
    "rf.cv_results_\n",
    "rf_predictions_h = rf.predict(X_Test_h)\n",
    "rf.score(X_Test_h, Y_cnt_test_h)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8758574001887438"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    \"learning_rate\": [0.01, 0.1],\n",
    "    \"max_depth\": [4, 8, 12],\n",
    "    \"min_child_weight\": [3, 5, 10, 20, 35, 50],\n",
    "    \"subsample\": [0.5, 0.75],\n",
    "    \"colsample_bytree\": [0.5, 0.75],\n",
    "    \"n_jobs\": [-1],\n",
    "    \"n_estimators\": [100, 300],\n",
    "    \"random_state\": [random_seed],\n",
    "}\n",
    "model = xgb.XGBRegressor()\n",
    "\n",
    "xg = dcv.GridSearchCV(model, param_grid=param_grid, cv=tscv, n_jobs=-1, scoring=\"r2\")\n",
    "with joblib.parallel_backend(\"dask\"):\n",
    "    xg.fit(X_Train_h, Y_cnt_train_h)\n",
    "    \n",
    "para = xg.best_params_\n",
    "\n",
    "xg = dxgb.XGBRegressor(\n",
    "    learning_rate=para[\"learning_rate\"],\n",
    "    max_depth=para[\"max_depth\"],\n",
    "    min_child_weight=para[\"min_child_weight\"],\n",
    "    subsample=para[\"subsample\"],\n",
    "    colsample_bytree=para[\"colsample_bytree\"],\n",
    "    n_estimators=para[\"n_estimators\"],\n",
    ")\n",
    "with joblib.parallel_backend(\"dask\"):\n",
    "    xg.fit(X_Train_h, Y_cnt_train_h)\n",
    "\n",
    "xg_predictions_h  = xg.predict(X_Test_h)\n",
    "xg.score(X_Test_h, Y_cnt_test_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_h = dd.concat([xg_predictions_h , hd_h[hd_h[\"instant\"] >= 15212][\"instant\"]] ,  axis = 1)\n",
    "real_pred_h = dd.concat([Y_cnt_test_h , hd_h[hd_h[\"instant\"] >= 15212][\"instant\"]] ,  axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final score after concatinating the 2 results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error (MSE): 4575.23\n",
      "Variance score (R2): 0.89\n"
     ]
    }
   ],
   "source": [
    "pred = pred_h.append(pred_w)\n",
    "real_pred = real_pred_h.append(real_pred_w)\n",
    "print(\"Mean squared error (MSE): {:.2f}\".format(mean_squared_error(real_pred['cnt'], pred['predictions'])))\n",
    "print(\"Variance score (R2): {:.2f}\".format(r2_score(real_pred['cnt'], pred['predictions'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
